{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26dd11a-a557-4fe1-b7f9-c69710d8957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hello, this is an intro to NLTK. If this is already familiar to you, feel free to skip this.\n",
    "# Ayman Haque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a5b219-8482-4603-ab67-4f27ffdf006b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855693d7-3249-48f3-9c1d-a9737a3effec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"book\")\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f32cb61-dc5a-4984-b55b-907f5a09efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if import went through\n",
    "texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c205844-1f55-4814-a81e-eac05940b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) find out the similar word of \"freedom\" in text4\n",
    "text4.similar(\"freedom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b48c38-59c8-4b53-a43b-01aa2ac79a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) how many times that the word \"computer\" appeared in text5\n",
    "text5.count(\"computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6c71aa-9b20-47b5-b93a-dfff25c7c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) what's the lexical diversity for text8\n",
    "def lexical_diversity(text): \n",
    "    return len(set(text)) / len(text)\n",
    "lexical_diversity(text8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96838b31-6bf2-4d23-938e-f38f98772ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) generate frenquency dictionary for text9 & plot the frequency distribution for the\n",
    "# top 20 words\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(text9)\n",
    "fdist\n",
    "fdist.plot(20, cumulative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406c442-ebf2-400c-9bed-09d1b93134ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) list all the words in text 7 that appeared more than 20 times and less than 100\n",
    "# times\n",
    "var = FreqDist(text7)\n",
    "filtered_words = [word for word, freq in var.items() if 20 < freq < 100]\n",
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17bad9a-280a-404c-b853-e7362bac03b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7bc1a2-34a0-4ea6-a412-6a5eb5559e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Extract & parsing the text data from “https://www.cdc.gov/flu/season/faq-flu-\n",
    "# season-2023-2024.htm”\n",
    "from urllib import request\n",
    "url = \"https://www.cdc.gov/flu/season/faq-flu-season-2023-2024.htm\"\n",
    "html = request.urlopen(url).read().decode('utf8')\n",
    "html[:1000]\n",
    "from bs4 import BeautifulSoup\n",
    "raw = BeautifulSoup(html, 'html.parser').get_text()\n",
    "raw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d248ea-2247-4437-aae0-bd79ef403e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Apply word tokenization to the file\n",
    "from nltk import word_tokenize\n",
    "tokens = word_tokenize(raw)\n",
    "type(tokens)\n",
    "len(tokens)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca0367-bb2f-40be-b863-f67f9f3ef1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Normalize all tokens into lowercase & apply wordnet Lemmatization to the\n",
    "# tokens\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "tokens = word_tokenize(raw)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "normalized_tks = [lemmatizer.lemmatize(token.lower()) for token in tokens]\n",
    "normalized_tks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33377040-e3b0-49e9-af58-48818fcced88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Generate vocabulary (distinct words after normalization & lemmatization), and\n",
    "# write the vocabulary to the text file \"vocab.txt\"\n",
    "vocabulary = set(normalized_tks)\n",
    "\n",
    "# Write the vocabulary to the text file \"vocab.txt\"\n",
    "with open(\"vocab.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for word in vocabulary:\n",
    "        file.write(word + \"\\n\")\n",
    "\n",
    "with open(\"vocab.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    outputFile = file.read()\n",
    "print(outputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e0c0f-c81c-4b5c-a708-caffaef1fc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
